# Week 3: Vector Space Models â€“ NLP Specialization

This repository contains my completed work for **Week 3** of the NLP course, covering **Vector Space Models**. It includes videos, readings, interactive labs, and a graded final assignment. All labs and assignments were implemented using Python and Numpy.

---

## ğŸ“š Topics Covered

### ğŸ”¸ Vector Space Models
- Understanding words as vectors in high-dimensional spaces
- Word-Word and Word-Document co-occurrence matrices
- Introduction to dense word embeddings

### ğŸ”¸ Linear Algebra Foundations
- Matrix operations with NumPy
- Mean centering, dot products
- Cosine similarity vs Euclidean distance

### ğŸ”¸ Word Similarity
- Calculating cosine similarity between word vectors
- Finding relationships like `King - Man + Woman â‰ˆ Queen`

### ğŸ”¸ Word Embedding Manipulation
- Vector arithmetic for word analogies
- Embedding subset selection using `gensim` + `nltk`

### ğŸ”¸ Dimensionality Reduction & PCA
- Understanding Principal Component Analysis (PCA)
- Reducing 300D word embeddings to 2D for visualization
- Efficient PCA using SVD

---

## ğŸ§ª Labs Completed

| Lab | Description |
|-----|-------------|
| Euclidean Distance | Implemented Euclidean distance for word vectors |
| Cosine Similarity | Calculated cosine similarity manually using NumPy |
| Manipulating Word Embeddings | Performed vector arithmetic and analogies |
| Visualization & PCA | Implemented PCA (eigen and SVD approaches) for word embedding reduction |

---

## ğŸ“ˆ Final Graded Assignment: Vector Space Models
- âœ… **Submitted**
- ğŸ† **Grade: 80%**
- Implemented the full pipeline:
  - Loading and filtering word embeddings
  - Calculating cosine similarity
  - Predicting analogies like `"Athens - Greece + France â‰ˆ Paris"`
  - Computing PCA to visualize embedding spaces

---

## ğŸ›  Technologies Used
- Python 3
- NumPy
- Pandas
- Matplotlib (for optional visualization)
- Gensim (for loading pre-trained word vectors)
- NLTK (for tokenization)

---
